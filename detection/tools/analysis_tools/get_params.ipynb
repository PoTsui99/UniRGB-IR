{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zhangguiwei/anaconda3/envs/detrex/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# 计算每个 component 参数的数量及未冻结参数占骨干网络的比例\n","import torch\n","# adapter_whole = '/path/to/codes/mmdet-VPT/work_dirs/FLIR/Ablation/flir_ablate_stage4/768_stage4_3-25/best_coco_bbox_mAP_iter_22000.pth'\n","# adapter_whole = torch.load(adapter_whole, map_location='cpu')\n","\n","# ch6 = '/path/to/codes/mmdet-VPT/work_dirs/FLIR/Ablation/768_6chans_4-7/best_coco_bbox_mAP_iter_20500.pth'\n","# ch6 = torch.load(ch6, map_location='cpu')\n","\n","vitv15_full = '/path/to/codes/mmdet-VPT/work_dirs/FLIR/Ablation/1024_fullfinetune_3-23/best_coco_bbox_mAP_iter_44500.pth'\n","vitv15_full = torch.load(vitv15_full, map_location='cpu')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["vitv15_full_back = {k[9:]: v for k, v in vitv15_full['state_dict'].items() if 'backbone' in k}\n","vit_values = []\n","for k in vitv15_full_back.keys():\n","    if 'num_batches_tracked' not in k:  # batch norm 的参数, 不用考虑\n","        vit_values.append(vitv15_full_back[k])\n","# vitv15_full_back_params = [*vitv15_full_back.values()]\n","# vitv15_full_back_params[0]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["adapter_back = {k[9:]: v for k, v in adapter_whole['state_dict'].items() if 'backbone' in k}\n","ch6_back = {k[9:]: v for k, v in ch6['state_dict'].items() if 'backbone' in k}"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["adapter_unfreeze = []\n","adapter_unfreeze_keys = []\n","for k in adapter_back.keys():\n","    if 'prompt' in k or 'adapter' in k:\n","        if 'num_batches_tracked' not in k:  # batch norm 的参数, 不用考虑\n","            adapter_unfreeze.append(adapter_back[k])\n","            adapter_unfreeze_keys.append(k)\n","\n","ch6_unfreeze = [*ch6_back.values()]\n","ch6_unfreeze_keys = [*ch6_back.keys()]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["128"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(adapter_unfreeze)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["171"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(ch6_unfreeze)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(94779088)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["def get_params(tensor_list):\n","    n_params = 0\n","    for i in tensor_list:\n","        shape = torch.tensor(i.shape)\n","        n_floats = torch.prod(shape)\n","        n_params += n_floats\n","    return n_params\n","        \n","# get_params(adapter_unfreeze), get_params(ch6_unfreeze) # 8.91M, 86.46M\n","get_params(vit_values) # 94.78M"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# 按照 part 保存参数(tensor)\n","head_tensors = []  # params except backbone, 包含 RPN head 和 RoI head\n","prompter_tensors = []\n","vit_tensors = []\n","\n","for k in full_weight['state_dict']:\n","    tensor = full_weight['state_dict'][k]\n","    if 'backbone' not in k:\n","        head_tensors.append(tensor)\n","    else:\n","        if 'prompt' in k or 'adapter' in k:\n","            if 'num_batches_tracked' not in k:  # batch norm 的参数, 不用考虑\n","                prompter_tensors.append(tensor)\n","        else:\n","            vit_tensors.append(tensor)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(94, 128, 171)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(head_tensors), len(prompter_tensors), len(vit_tensors)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["n_floats_head = 0\n","n_floats_prompter = 0\n","n_floats_vit = 0\n","\n","for i in head_tensors:\n","    shape = torch.tensor(i.shape)\n","    n_floats = torch.prod(shape)\n","    n_floats_head += n_floats.item()\n","    \n","for i in prompter_tensors:\n","    shape = torch.tensor(i.shape)\n","    n_floats = torch.prod(shape)\n","    n_floats_prompter += n_floats.item()\n","    \n","for i in vit_tensors:\n","    shape = torch.tensor(i.shape)\n","    n_floats = torch.prod(shape)\n","    n_floats_vit += n_floats.item()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["(52390887, 8906448, 85889024)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["n_floats_head, n_floats_prompter, n_floats_vit"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["0.10369716158376652"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["n_floats_prompter / n_floats_vit  # only adding 10.37% learnable params to backbone."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 全部参数: 147,186,359\n","# 放开参数占整个检测器比例(prompter+head): 41.65%\n","# 放开参数(prompter)占整个backbone(prompter+ViT)比例: 9.40%\n","# 放开参数(prompter)占ViT比例: 10.37%"]}],"metadata":{"kernelspec":{"display_name":"detrex","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":2}
